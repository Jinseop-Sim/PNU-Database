# Statistical Inference
---
> 먼저 Data Science의 Process에는 어떤 것이 있었나?  

1. Ask a Question
2. Form a Hypothesis
3. Experiment, Observation, Analysis
4. Deploy and Evaluate (Loop Branch)
5. Make Decision / Scoring, Monitoring

- 위의 과정이 계속 반복되는 것이 Data Science이다.
- 1번과 2번 과정이 제대로 이루어지지 않으면, 뒤의 과정이 모두 꼬이게 된다.
  - 따라서 양질의 질문을 하고 양질의 가설을 세우는 것은 매우 중요한 일이다!

## Data and Sampling Distribution
> 통계적 추론이라 함은, 채취된 표본을 통해 거꾸로 모집단의 분포를 예측하는 것이다.  

- 추정 : 표본의 통계 측정치를 통해 모집단의 분포를 추정하는 것.
- 가설 검정 : 모수적 방법, 비모수적 방법이 존재

### Random Sampling
> 모집단 내의 선택 가능한 원소들을 무작위로 추출하는 과정.  
> 그 결과로 얻은 표본을 __단순 랜덤 표본__ 이라고 한다.  

- 표본추출
  - 비복원 추출 : 추출했던 원소를 다시 포함시키지 않는다. (표본의 크기가 작을 때 사용하면 위험)
  - 복원 추출 : 추출했던 원소를 다시 모집단에 포함시켜 재추출을 허용하는 추출.
- 표본의 편향(Bias) 정도에 따라 데이터의 품질이 달라지기 때문에, __대표성(Representiveness)__ 이라는 개념을 추가한다.
  - ex) 1,000만명을 상대로 조사를 했을 때 LANDON이 승리하리라 생각했지만, Roosvelt가 승리했다.
  - 이 대표성을 확보하기 위해, Random Sampling을 하는 것!

### Size vs Quality
> 언제 작은 데이터가 더 유리할까?  

- 아무리 Big Data의 시대라고 해도, 적은 데이터의 수가 더 유리한 경우가 있다.
  - Random Sampling에 시간과 노력을 기울일 수록 Bias가 줄어들고 Data의 품질이 매우 상승한다.
  - 몇 백만개의 Data 중에서 이를 하는 것은 매우 어려운 일이지만 수 천개의 Sample에서는 충분히 가능한 일이다.
- Data가 커서 유리한 경우는 무엇이 있을까?
  - Data가 크고 동시에 희박할 때이다.
  - Example : Google이 입력 받은 검색 쿼리를 처리하는 상황.
    - 발생 빈도가 매우 낮은 Query라도 사용자가 요청하면 응답을 해야만 한다.
    - 따라서 대부분이 0으로 가득 채워져있는 거대한 행렬을 Big Data로 갖고 있어야 제대로 응답이 가능하다.

## Big Data?
> Big Data의 __"Big"__ 은 절대값을 정의하는 것이 무의미한 상대적인 개념이다.  

- __"Big"__ 은 하나의 기계로 처리할 수 없을 때 적용한다.
  - Data가 너무 방대해서 하나의 컴퓨터로는 처리할 수 없을 때, Big Data라고 간주한다.
  - 시대에 따라 Big의 기준이 바뀌게 될 것이다.
- __Big Data__ 는 문화적 현상이다.
  - 얼마나 많은 Data가 생활의 일부를 이루고 있는지 보여준다.
- 4V
  - Volume, Variety, Velocity, Value
  - Big Data를 규정하는 하나의 방식으로 이 용어들을 이용한다.

## Statistical Inference Example : 수면제 효과 연구
- 문제 : 숙면에 도움을 주기 위해 개발한 약의 효과
- 표본 : 각각 10명의 실험 지원자로 구성된 2개의 그룹
  - 실험 지원자가 약을 먹었을 때 증가한 수면 시간 측정
  - Between Subjects : 두 그룹에 다른 약을 먹인다.
  - Within Subjects : 두 그룹에게 A를 먹인 뒤, 시간이 지나고 B를 다시 먹인다.
- EDA의 주요 결과
  - 10명 중 4명은 수면시간 감소, 6명은 증가
  - 평균 0.75시간의 수면시간 증가
  - 표본 표준 편차(Sample Standard Deviation)은 1.8시간
  - 데이터 분포에서 약간의 Bimodality(KDE, 봉우리 2개)가 보이는 것 외에 특이사항 없음.
- 그런데 이는, __수면제의 효과에 대한 의미있는 설명__ 으로 이어지지 못한다.
  - 따라서 통계적 작업이 필요하다.

### Statistical Inference
> *이 수면제는 효과가 있는가?  

- 가설 검정(Hypothesis Test)
  - 검정 : 검사하여 정함, 규칙에 따라 자격이나 조건을 검사함.
  - 검증 X
- 신뢰 구간(Confidence Interval) : 이 수면제의 효과는 얼마인가?
- 예측(Prediction) : 누군가 다른 사람이 이 수면제를 복용하면 어떤 효과가 있을 것인가?

### One-sample T-test
- ```ttest_1samp(a, popmean, alternative='two-sided')
  - a : 대상 데이터
  - popmean : Population Mean, 모집단 평균
  - alternative : Default는 'Two-Sided'이다. (Less, Greater도 있음)
- 결과 값
  - Statistic : T-통계량
  - Pvalue : P-value
- 함수의 호출 자체는 쉽지만, 해석하는 것이 어렵다!
---
### P-value?
- T-test의 결과와 P-value의 의미
  - P-Value란, 귀무가설이 맞다는 전제 하에, 통계값이 실제 관측 값 이상일 확률을 의미한다.
    - 특정 가설을 세웠을 때, 밀도 함수 그래프에서 그 가설보다 큰 부분의 값을 의미한다. 
    - A와 B를 비교했을 때, P-value가 낮게 나오면 그 가설은 신뢰구간에서 멀다는 의미이므로 기각한다.
    - 반대로 P-value가 크게 나오면 가설은 신뢰구간에 포함된다는 말이므로 채택한다.
  - Two-sided : 약이 수면 시간 변화에 효과가 없는데, 이러한 표본 평균 수면 시간 변화의 관측 확률은 21.75%이다.
  - Greater : 약이 수면 시간 증가에 효과가 없는데 이러한 표본 평균 수면 시간 변화의 관측 확률이 10.87%이다.
- __지식의 저주__
  - __자신이 알고있는 정보를, 당연히 다른 사람도 알 것이라는 고정관념에서 나오는 인식의 왜곡__
---

## About Statistics
### 첫째, 통계학은 숨겨진 진실을 추구한다.
- 알려지지 않은 참값이 있음을 가정한다.
  - 모집단의 알려지지 않은 참값이 있음을 가정한다.
  - ex) Population Mean
  - 통계적 추정 : 불완전한, 잡음이 섞인 Data로부터 숨겨진 진실을 찾는 작업.
- 가설 검정 : 수면제는 효과가 있는가?
  - 모수(진실)에 대한 두 가지 가설
  - Popmean = 0 : 수면제는 효과가 없다.(귀무가설, Null Hypothesis)
  - Popmean > 0 : 수면제는 수면 시간을 늘리는 데에 효과가 있다. (대립가설, Alternative Hypothesis)
    - 대립가설이 우리가 보이고 입증하고 싶은 가설.
- 가설 검정과 무죄추정의 원칙
  - 귀무가설 : 무죄.
    - 증거 불충분
  - 대립가설 : 유죄
    - 귀무가설과 대립되는 증거가 많으면 많을수록, 유죄임을 선고하기가 쉬워진다.
    - 즉, 귀무가설 하에 관측되기 어려운 데이터 값이 많이 관측될 수록 유죄임을 선고하기가 쉽다!
 
### 둘째, 통계학은 불확실성을 인정한다.
- 통계학적이지 않은 결론
  - 이 수면제는 수면시간을 늘리는 효과가 있다.
  - 평균 수면시간의 증가는 0.75시간 이다.
  - 통계학은 이렇게 확실하게 결론 내리지 않는다.
- 통계학의 __겸손한__ 대답(__Uncertainty__)
  - 이 수면제가 효과가 없는데, 이렇게 큰 표본 평균 수면 시간 증가가 관측될 확률은 11%이다.(P-value)
  - 평균 수면시간의 증가에 대한 95% 신뢰구간은 [-0.53, 2.03] 이다.
- 통계학은 어렵다.
  - 사람은 직관적인 시스템(Fast Thinking)이 발달하는 쪽으로 진화했다.
    - 하지만 통계학은 Slow Thinking으로, 우리의 평이한 본성과는 거리가 있다.
