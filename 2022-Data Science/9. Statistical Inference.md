# Statistical Inference
---
> 먼저 Data Science의 Process에는 어떤 것이 있었나?  

1. Ask a Question
2. Form a Hypothesis
3. Experiment, Observation, Analysis
4. Deploy and Evaluate (Loop Branch)
5. Make Decision / Scoring, Monitoring

- 위의 과정이 계속 반복되는 것이 Data Science이다.
- 1번과 2번 과정이 제대로 이루어지지 않으면, 뒤의 과정이 모두 꼬이게 된다.
  - 따라서 양질의 질문을 하고 양질의 가설을 세우는 것은 매우 중요한 일이다!

## Data and Sampling Distribution
> 통계적 추론이라 함은, 채취된 표본을 통해 거꾸로 모집단의 분포를 예측하는 것이다.  

- 추정 : 표본의 통계 측정치를 통해 모집단의 분포를 추정하는 것.
- 가설 검정 : 모수적 방법, 비모수적 방법이 존재

### Random Sampling
> 모집단 내의 선택 가능한 원소들을 무작위로 추출하는 과정.  
> 그 결과로 얻은 표본을 __단순 랜덤 표본__ 이라고 한다.  

- 표본추출
  - 비복원 추출 : 추출했던 원소를 다시 포함시키지 않는다. (표본의 크기가 작을 때 사용하면 위험)
  - 복원 추출 : 추출했던 원소를 다시 모집단에 포함시켜 재추출을 허용하는 추출.
- 표본의 편향(Bias) 정도에 따라 데이터의 품질이 달라지기 때문에, __대표성(Representiveness)__ 이라는 개념을 추가한다.
  - ex) 1,000만명을 상대로 조사를 했을 때 LANDON이 승리하리라 생각했지만, Roosvelt가 승리했다.
  - 이 대표성을 확보하기 위해, Random Sampling을 하는 것!

### Size vs Quality
> 언제 작은 데이터가 더 유리할까?  

- 아무리 Big Data의 시대라고 해도, 적은 데이터의 수가 더 유리한 경우가 있다.
  - Random Sampling에 시간과 노력을 기울일 수록 Bias가 줄어들고 Data의 품질이 매우 상승한다.
  - 몇 백만개의 Data 중에서 이를 하는 것은 매우 어려운 일이지만 수 천개의 Sample에서는 충분히 가능한 일이다.
- Data가 커서 유리한 경우는 무엇이 있을까?
  - Data가 크고 동시에 희박할 때이다.
  - Example : Google이 입력 받은 검색 쿼리를 처리하는 상황.
    - 발생 빈도가 매우 낮은 Query라도 사용자가 요청하면 응답을 해야만 한다.
    - 따라서 대부분이 0으로 가득 채워져있는 거대한 행렬을 Big Data로 갖고 있어야 제대로 응답이 가능하다.

## Big Data?
> Big Data의 __"Big"__ 은 절대값을 정의하는 것이 무의미한 상대적인 개념이다.  

- __"Big"__ 은 하나의 기계로 처리할 수 없을 때 적용한다.
  - Data가 너무 방대해서 하나의 컴퓨터로는 처리할 수 없을 때, Big Data라고 간주한다.
  - 시대에 따라 Big의 기준이 바뀌게 될 것이다.
- __Big Data__ 는 문화적 현상이다.
  - 얼마나 많은 Data가 생활의 일부를 이루고 있는지 보여준다.
- 4V
  - Volume, Variety, Velocity, Value
  - Big Data를 규정하는 하나의 방식으로 이 용어들을 이용한다.

## Statistical Inference Example : 수면제 효과 연구
- 문제 : 숙면에 도움을 주기 위해 개발한 약의 효과
- 표본 : 각각 10명의 실험 지원자로 구성된 2개의 그룹
  - 실험 지원자가 약을 먹었을 때 증가한 수면 시간 측정
  - Between Subjects : 두 그룹에 다른 약을 먹인다.
  - Within Subjects : 두 그룹에게 A를 먹인 뒤, 시간이 지나고 B를 다시 먹인다.
- EDA의 주요 결과
  - 10명 중 4명은 수면시간 감소, 6명은 증가
  - 평균 0.75시간의 수면시간 증가
  - 표본 표준 편차(Sample Standard Deviation)은 1.8시간
  - 데이터 분포에서 약간의 Bimodality(KDE, 봉우리 2개)가 보이는 것 외에 특이사항 없음.
- 그런데 이는, __수면제의 효과에 대한 의미있는 설명__ 으로 이어지지 못한다.
  - 따라서 통계적 작업이 필요하다.

### Statistical Inference
> *이 수면제는 효과가 있는가?  

- 가설 검정(Hypothesis Test)
  - 검정 : 검사하여 정함, 규칙에 따라 자격이나 조건을 검사함.
  - 검증 X
- 신뢰 구간(Confidence Interval) : 이 수면제의 효과는 얼마인가?
- 예측(Prediction) : 누군가 다른 사람이 이 수면제를 복용하면 어떤 효과가 있을 것인가?

### One-sample T-test
- ```ttest_1samp(a, popmean, alternative='two-sided')
  - a : 대상 데이터
  - popmean : Population Mean, 모집단 평균
  - alternative : Default는 'Two-Sided'이다. (Less, Greater도 있음)
- 결과 값
  - Statistic : T-통계량
  - Pvalue : P-value
- 함수의 호출 자체는 쉽지만, 해석하는 것이 어렵다!
---
### P-value?
- T-test의 결과와 P-value의 의미
  - P-Value란, 귀무가설이 맞다는 전제 하에, 통계값이 실제 관측 값 이상일 확률을 의미한다.
    - 특정 가설을 세웠을 때, 밀도 함수 그래프에서 그 가설보다 큰 부분의 값을 의미한다. 
    - A와 B를 비교했을 때, P-value가 낮게 나오면 그 가설은 신뢰구간에서 멀다는 의미이므로 기각한다.
    - 반대로 P-value가 크게 나오면 가설은 신뢰구간에 포함된다는 말이므로 채택한다.
  - Two-sided : 약이 수면 시간 변화에 효과가 없는데, 이러한 표본 평균 수면 시간 변화의 관측 확률은 21.75%이다.
  - Greater : 약이 수면 시간 증가에 효과가 없는데 이러한 표본 평균 수면 시간 변화의 관측 확률이 10.87%이다.
- __지식의 저주__
  - __자신이 알고있는 정보를, 당연히 다른 사람도 알 것이라는 고정관념에서 나오는 인식의 왜곡__
---

## About Statistics
### 첫째, 통계학은 숨겨진 진실을 추구한다.
- 알려지지 않은 참값이 있음을 가정한다.
  - 모집단의 알려지지 않은 참값이 있음을 가정한다.
  - ex) Population Mean
  - 통계적 추정 : 불완전한, 잡음이 섞인 Data로부터 숨겨진 진실을 찾는 작업.
- 가설 검정 : 수면제는 효과가 있는가?
  - 모수(진실)에 대한 두 가지 가설
  - Popmean = 0 : 수면제는 효과가 없다.(귀무가설, Null Hypothesis)
  - Popmean > 0 : 수면제는 수면 시간을 늘리는 데에 효과가 있다. (대립가설, Alternative Hypothesis)
    - 대립가설이 우리가 보이고 입증하고 싶은 가설.
- 가설 검정과 무죄추정의 원칙
  - 귀무가설 : 무죄.
    - 증거 불충분
  - 대립가설 : 유죄
    - 귀무가설과 대립되는 증거가 많으면 많을수록, 유죄임을 선고하기가 쉬워진다.
    - 즉, 귀무가설 하에 관측되기 어려운 데이터 값이 많이 관측될 수록 유죄임을 선고하기가 쉽다!
 
### 둘째, 통계학은 불확실성을 인정한다.
- 통계학적이지 않은 결론
  - 이 수면제는 수면시간을 늘리는 효과가 있다.
  - 평균 수면시간의 증가는 0.75시간 이다.
  - 통계학은 이렇게 확실하게 결론 내리지 않는다.
- 통계학의 __겸손한__ 대답(__Uncertainty__)
  - 이 수면제가 효과가 없는데, 이렇게 큰 표본 평균 수면 시간 증가가 관측될 확률은 11%이다.(P-value)
  - 평균 수면시간의 증가에 대한 95% 신뢰구간은 [-0.53, 2.03] 이다.
- 통계학은 어렵다.
  - 사람은 직관적인 시스템(Fast Thinking)이 발달하는 쪽으로 진화했다.
    - 하지만 통계학은 Slow Thinking으로, 우리의 평이한 본성과는 거리가 있다.

### 셋째, 통계학은 관측된 데이터가 가능한 여러 값 중 하나라고 생각한다.
- 현재 관측한 데이터는 모집단에서 관측될 수 있는 여러 가능한 데이터 중 하나다. (자명)
- Simulation으로 아주 많은 Sample을 생성하자.
  - Simulation : 주어진 가정하에 여러 현실을 만들어보는 작업
  - Example : 모집단 모델링(Gaussian / Normal)
    - 수면제 효과가 없다.(평균 = 0)
    - 표준편차(STD)가 1.8시간.
    - N(0, 1.8^2)
- Sample들의 Statistic을 구하자
  - T-statistic
- Prob(T >= t)
  - 앞서 T-test에서 구한 결과
    - T-statistic = 1.3257101407..
    - p-value = 0.108798890034.. (Alternative = 'greater')
  - T-statistic 값이 1.3257101407.. 보다 큰 비율이 P-value에 거의 부합한다!
  - 즉 Prob(T >= t)가 P-value가 된다.
---
### 용어 정리
- 모집단(Population) : 알고 싶은 값이 나올 수 있는 전체 집단.
- 모수(Population Parameter) : 모집단을 설명하는 어떤 숫자. (ex) Mean, STD)
- 표본(Sample) : 모집단의 일부를 Random Sampling 과정을 통해 추출한 집단
  - Sample의 통계량을 통해 모집단의 통계량을 추정한다.
- 통계량(Statistics) : Mean, STD, T-statistics등의 그 집단이 가지는 수치적 특성, 가설 검정에 사용이 된다.
- 귀무가설(Null Hypothesis) : H0 라고 보통 표기하며, 모평균이 0이라고 가정하는 가설.
  - 우리가 일반적으로 검정하고 싶은 가설에 반대되도록 가설을 세운다.
- 대립가설(Alternative Hypothesis) : 귀무가설과 대립되는 가설로, H1이라고 보통 표기한다.
  - 우리가 일반적으로 검정하고 싶은 가설이다.
  - Two-sided Alternative : Mean != 0
  - One-sided Alternavie : Mean > 0 (greater), Mean < 0 (less)
- Type-1 Error(False Positive) : 귀무가설이 옳은 데, 틀렸다고 판단하는 Error (Prob = alpha)
  - 수면제 효과가 실제로 없을 때(귀무가설이 옳을 때), 효과가 있다고 판단하는 경우
- Type-2 Error(False Negative) : 귀무가설을 Reject했는데, 옳다고 판단하는 Error
  - 수면제 효과가 실제로 있을 때(귀무가설을 Reject 할 때), 효과가 없다고 판단하는 경우
- 유의 수준(Significance level, Alpha) : 위 Error가 발생할 확률
  - Error가 발생하지 않고 올바른 값이 나올 확률은 (1-Alpha)

### 용어 사용의 예시 : 수면 시간 증가 문제
- 모집단 : 무수히 많은 수면 환자들
- 모수 : 무수히 많은 수면 환자들의 평균 수면 시간 증가
- 표본 : Random하게 추출한 10명
- 통계량 : 표본의 평균 수면시간 증가
- 귀무가설 : 주어진 수면제는 수면시간 증가에 효과가 없다.
- 대립가설 : 주어진 수면제는 수면시간 증가에 효과가 있다.
- Type-1 Error : 실제로 수면제 효과가 없을 때 효과가 있다고 결론짓는 오류
- Type-2 Error : 실제로 수면제 효과가 있을 때 효과가 없다고 결론짓는 오류
- P-value : 실제로 수면제의 효과가 없을 때, 평균 수면시간 증가가 표본의 통계량이 보여준 것만큼 클 확률.
---

## Student's T-distribution
- Z-Statistics
  - Data : 독립적이고, IID Gaussian 분포를 따른다.
  - N(mean, STD^2) ==> 귀무 가설이 참이 되면, 이는 정규분포를 따른다.
  - 문제점 : 모집단의 STD를 알기 어렵다.
- T-Statistics
  - William Gosset이 맥주의 품질을 모니터하기 위한 방법으로 개발
  - T(v), v = 자유도 n-1, 자유도가 커질 수록 정규분포에 근사한다.
    - 자유도가 작을수록 꼬리부분이 두터워진다.

## T-Test
- 통계적 가설 검정.
  - Test 통계량이 T-distribution이 따를 때 적용한다.
- 가정
  1. 각 관측치가 모두 독립적이고
  2. 동일한 분포를 따르며
  3. 그 분포는 정규 분포여야 한다.
- Table을 이용하여 계산한다.
  - 컴퓨터의 보급과 활용이 보편화되기 이전엔 그랬다.

### T-test 해석
- 판단의 기준
  - 유의 수준 Alpha
    - Alpha : 10%, 5%, 1%..
  - One-side T-test 기준
    - P-value < Alpha : Reject Null
    - P-value > Alpha : Don't Reject Null, 통계적으로 유의하다.

### P-value의 오해와 남용
- P-value보다 유의성만 보고하는 오류
  - Alpha가 0.05일 때, P-value가 각각 0.049 0.051 으로 나왔을 때, 둘이 서로 다른 결과를 보고하게 된다.
  - Reject 여부만 보고하는 것이 아닌 P-value 자체를 보고함이 필요하다.
- P-value만을 고려하고 신뢰구간을 사용하지 않는 오류
- P-value를 모수에 대한 확률로 이해하는 오류
  - 그 수면제가 효과가 있을 확률이 95%이다.
    - Alpha를 0.05로 가정했을 때, 위의 결과를 보고한다.
  - 그 수면제가 효과가 없다는 귀무가설이 맞을 확률이 95%이다.
    - 이 또한 잘못된 해석이다.
- 높은 P-value를 귀무가설이 옳다는 증거로 이해하는 오류.
  - 단지 증거의 불충분을 의미할 뿐이다.
- 낮은 P-value가 항상 유의하다고 이해하는 오류
  - 낮은 P값을 얻었는데 평균 수면 시간 증가가 1초라면? 크게 유의한 값은 아니다.
  - Data가 커지면 커질 수록 일반적으로 P값은 작아진다.
    - 즉, 가설검정의 민감도가 커진다.
