# Data wrangling
---
> 좋은 Data Scientist들은 대부분 그들의 시간을 데이터를 정리하고 Formatting 하는데에 쓴다.  
> 남은 시간은 쓸 수 없는 데이터에 대한 Complain을 건다.  
> __Data munging__ , __Data wrangling__ 은 분석을 위해 Data를 수집하고 준비함에 있어 예술이다.  
> _Steven SKiena_  

- Wrangle : 오랫동안 다투다.
- Munging : 개조한다, 변경한다.

## When do we perform Data wrangling?
- Data wrangling은 모든 단계에서 다양한 형태로 행해진다.
  - ex) Collect 과정에서 Email 정보를 가져와서 Tokenize 하는 동작.
  - ex) Data process 과정에서 Web-Scraping을 하는 동작. Munging, Wrangling 하는 동작.

## Data Cleaning
- Missing, Incorrect Data에 대한 처리 방법이다.
  - NaN : Not a Number
  - 키를 측정하는데에 있어서 음수.. etc..
- 대처 방법(Possible action)
  - 행(row)를 통째로 제거한다.
  - 열(Column, variable)을 통째로 제거한다.
  - Missing, Incorrect Value들을 다른 값으로 대체한다.(Data imputation)
    - ex) Proper values like Mean, Median, Mode, kNN(가장 정확)
  - 뒷 과정으로 넘긴다. (그냥 둔다.)

### Data Cleaning Example 
####  ```isnull()``` 함수의 이용
```python
import numpy as np
import pandas as pd

np.random.seed(48)
df = pd.DataFrame(10*np.random.rand(4,2).round(2))
df.columns = ["A", "B"]

df.A[1] = np.nan

df.isnull() # 이 출력 결과를 이용해 어디에 Missing Data가 있는지 알 수있다.
df.isnull().sum # 이 결과는 각 Column에 몇 개의 Missing Data가 있는지 총 갯수를 알려준다
```  

#### ```dropna()``` 함수의 이용
```python
df2 = df.dropna() # Missing Data가 있는 Row를 제거한다.
df.dropna(axis=1)) # Missing Data가 있는 Column을 통째로 제거한다.
df.dropna(how="all") # Default는 "any"로 "all" 적은 경우엔 어떤 행이나 열의 Feature이 모두 Missing이면 지운다.
df.dropna(thresh=3, axis=1) # 역치 값을 준다. thresh 값 이상의 Missing Data가 존재하는 경우, 그 Column을 삭제한다.
```  

#### Replacing Missing Value(Data Imputation)
- Mean, Median, Mode
- LOCF(Last Observation Carried Forward) : 마지막으로 관측된 값으로 똑같이 채운다.
- NOCB(Next Observation Carried Backward) : 다음 칸에 관측될 값으로 똑같이 채운다.
- Linear Interpolation
- kNN : 이웃을 검사해서 그들의 값을 이용한 계산 값으로 채운다.
- Arbitrary Value  

- ```fillna()``` 함수를 통한 Replacing
```python
df.fillna(0) # Missing Data가 0으로 모두 채워진다.
df.fillna(method="ffill") # Forward Fill, 자기 위의 값들로 똑같이 채워진다.
df.fillna(method="bfill") # Backward Fill, 자기 밑의 값들로 똑같이 채워진다.
df.fillna(method="ffill", axis=1) # axis=1이 되면, 옆 Column에서 값을 가져온다. Forward 이므로 자신의 앞 Column.
                                  # Column이 더 이상 존재하지 않는다면 그대로 NaN으로 둔다.
df.fillna(df.mean().round(2)) # Default는 Axis = 0, 모든 Row들의 평균을 계산한 뒤, NaN 값을 Replacing한다.
```

## Data Scaling
> Feature Scaling 이라고도 부른다.  
> 각 Data의 변화량 차이가 너무 큰 것을 표준화 시키는 일이다.  

![image](https://user-images.githubusercontent.com/71700079/166406222-a35f9c76-8069-4e63-8842-011c2546f2a5.png)  
- 위의 예시 사진과 같이 표준화를 시키는 것이다.

### Standardization
> Data의 분표를 정규화 시키는 것이다.  
> 평균이 0, 표준편차가 1이 되도록.  
![image](https://user-images.githubusercontent.com/71700079/166406409-218afaa6-9831-41e2-a811-406b769008d9.png)
![image](https://user-images.githubusercontent.com/71700079/166406332-f5e7b955-0f0f-42c6-ba01-597067c699ca.png)  

### Normalization : Min-Max Scaling
> 최대값과 최소값을 이용해서 Scaling을 한다.  
![image](https://user-images.githubusercontent.com/71700079/166406416-7c991939-3dcc-4ecb-8848-5d000428f909.png)
![image](https://user-images.githubusercontent.com/71700079/166406406-cfb93de6-bdf3-44e1-aac9-6350d49d5467.png)  

### How to find outliers?
- 1변량 : Boxplot / Standardization  
![image](https://user-images.githubusercontent.com/71700079/166407743-0ec1b2e9-f165-4949-a544-91d07984410a.png)
![image](https://user-images.githubusercontent.com/71700079/166407746-3bfdcd8f-fa03-4246-a131-c2e8966847bc.png)  
  - Boxplot : < 1.5 IQR
  - Standardization : < 3SD  

- 다변량(Multivariate) : Scatter Plot  
![image](https://user-images.githubusercontent.com/71700079/166407731-5314ca5b-21af-4b02-a4e6-5976c8eae691.png)  
  - Mahalanobis Distance  

## Data Encoding
> Numerical Variable을 Categorical Data로 바꾼다던지,  
> Categorical Data를 Numerical Variable로 바꾸는 등의 행동.  

- Numerical to Categoriacal
  - ex) Scores to Grades
- Categorical to Numerical
  - ex) Lable Encoding, One Hot Encoding(Set of binary Variables)
![image](https://user-images.githubusercontent.com/71700079/166408583-deca9b2a-7326-4496-a2fa-f6bcf3820a21.png)
