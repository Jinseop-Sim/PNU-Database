# Logistic Regression
---
> Logistic Regression(로지스틱 회귀)는 왜 사용하는가?  

- Linear Regression을 통해, Threshold를 두고 Classification을 하는 것은 성능이 그렇게 좋지 않다!
  - 따라서 Logistic Regression을 도입한다.
- Logistic Regression은, Linear Regression과 다르게 Categorical Data로 등장하게 된다.
  - ex) 시험에 Pass할 수 있는 확률에 대한 평가  

<p align = "center">
<img src = "https://user-images.githubusercontent.com/71700079/173174925-d89b198f-3160-4f16-b8d6-8c4fdc43e67c.PNG"> 
</p>

### Evaluation Metrics
- Precision(정밀도) : TP / TP + FP = 참이라고 결과가 나왔는데, 실제로 참일 확률 
- Accuracy(정확도) : TP + TN / (ALL) = 전체 검사 중, 제대로 검사했을 확률
- Recall(재현율) : TP / TP + FN = 실제로 참인데, 참이라고 평가했을 확률
- Fall out(위양성율) : FP / FP + TN = 실제로는 거짓인데, 참이라고 잘못 말했을 확률
- F1 Score = 2 * (Precision X Recall) / (Precision + Recall)

## Logistic Regression

- vs. Multiple Linear Regression
  - Multiple Linear Regression은 Numerical 값을 반환하는 반면, Logistic은 Binary 결과를 가진다.
  - Logistic Regression은 Data-centric Approach보다는, Structured model Approach이다.
- Key Terms
  - Odds (승산)
    - Success / Not Success : p / 1-p
  - Logit : Log-Odds
    - Logit(p) = Log(p/1-p) = -log(1/p - 1)
    - 여기서, Logistic 함수는 Logit(p)의 Inversion임을 알 수 있다!
- Where to use?
  - 예를 들면, COVID19에 대해서 X1 : Mask Wearing, X2 : Hand Washing, X3 : Exercise
  - Y : 0 - Not Infected, 1 - Infected
  - 상관 관계를 예측해볼 수 있다.

### How?
- Predictor X1, X2가 있다고 가정하자.
  - Binary Response Variable Y가 있을 때, p = P(Y=1)이라고 해보자.
  - Log(p/1-p) = B0 + B1X1 + B2X2, 좌측의 식이 선형의 관계를 갖는다고 가정한다.
  - 우리는 P를 Logit의 Inversion으로부터 정리할 수 있다. (Logistic 함수)
    - 이 때, B0 + B1X1 + B2X2 = 0 ==> p = 0.5
    - B0 + B1X1 + B2X2가 매우 크면, p ~ 1 (수렴)
    - B0 + B1X1 + B2X2가 매우 작으면, p ~ 0 (수렴)
  - 그럼 이 때 B0, B1, B2를 어떻게 구할 것인가?

### Maximum Likelihood
> Logistic Regression의 Coefficient를 구하는 방법.  

- Linear Regression은 간단하게 Slope와 Intercept(Coefficient)를 구할 수 있었지만, Logistic은 그렇지 못하다.
  - 따라서 Maximum Likelihood(최대 우도법)을 이용하여 계수를 구해내야 한다.
