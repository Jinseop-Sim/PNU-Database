# Naive Bayes
---
## Bayes' Theorem
> 확률을 Bayesian 관점에서 관찰한다.  
> 그 때 구해지는, 어떤 사건이 발생했을 때 특정 사건이 발생할 확률.  

- Bayesian 관점?
  - 선택된 표본이 특정 사건(부분 집합)에 속한다는 가설, 명제, 주장의 신뢰도
  - 확률처럼 반복이라는 개념이 존재하지 않는다.
  - ex) 동전 던지기 : 베이지안 관점으로 보면, 앞면이 나왔다는 주장의 신뢰도가 몇 %인지를 보는 것!
- Bayes' Theorem  
![image](https://user-images.githubusercontent.com/71700079/160537890-a8fcb331-3e62-4b18-84ac-93cef6b5c122.png)  
  - 위의 식은, B사건이 발생했을 때 A사건 또한 발생할 확률에 대한 식이다.
  - P(A|B) : 사후확률(Posterior) / 사건 B가 발생한 후 갱신되는 사건 A의 확률
  - P(A) : 사전확률(Prior), 가설(Hypothesis) / 사건 B가 발생하기 전의 사건 A의 확률
  - P(B|A) : 가능도, 우도(Likelihood) / 사건 A가 발생한 경우 사건 B의 확률
  - P(B) : 정규화 상수, 증거(Evidence) / 확률의 크기가 조정되는 Key
  - 결국 Evidence에 의해서 Hypothesis의 확률을 조정하는 과정이다.

### Expansion of Bayes' Theorem
> 만약 사건 Ai가 서로 배타적이고 완전하다면?  
- 전확률 정리(Law of total probability)를 이용하여 베이즈 정리를 확장.
![image](https://user-images.githubusercontent.com/71700079/161425719-fe6376a2-5b04-4b94-9fea-1589ad223314.png)  
- 사건 Ai들이 모두 독립이라는 가정 하에,
  - B & A1 + B & A2 + B & A3 + B & A4 = P(B)

- Example 1 : 검사 시약 문제

### Expansion of Bayes' Theorem 2
> 원래 베이즈 정리는 사건 A의 확률이 사건 B에 의해 갱신된 확률을 계산했다.  
> 하지만 추가적인 사건 C가 발생한다면?  

- Example 2 : Monty Hall Problem

## Naive Bayes Classifier
> Class들 중에 우리가 원하는 Class를 Bayes' Theorem을 통해 분류해내는 작업.  
> 어떤 Attribute들과 Class가 주어졌을 때, 어떤 Class가 될 확률을 묻는 것이다.  
- Example : 비가 올 확률
  - 기온이 높고 온도가 낮고 바람이 많이 불고 날씨가 좋은데 비가 올 확률이 얼마나 될까?  
  ![image](https://user-images.githubusercontent.com/71700079/161407624-cd9fd4e7-64f2-4255-b573-d79933bee54f.png)  

